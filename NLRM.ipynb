{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal Linear Regression Model\n",
    "\n",
    "Classic linear regression model:\n",
    "\n",
    "$y_i=x_i'\\beta+\\varepsilon_i$\n",
    "\n",
    "Assumptions:\n",
    "1. $\\varepsilon_i \\overset{iid}{\\sim} N(0,\\sigma^2)$\n",
    "2. $x_i \\perp \\varepsilon_j$\n",
    "\n",
    "$\\Rightarrow f(y_i \\mid x_i,\\beta,\\sigma^2) \\sim N(x_i\\beta,\\sigma^2)$ is the likelihood function\n",
    "\n",
    "\n",
    "\n",
    "Since $\\varepsilon_i$ and $\\varepsilon_j$ are independent $\\forall i \\neq j$ and $y-X\\beta = y-X(\\beta-\\hat{\\beta})-X\\hat{\\beta} $:\n",
    "\n",
    "\n",
    "$f(y \\mid x,\\beta,\\sigma^2) = \\frac{1}{(2\\pi)^{n/2}\\sigma^{n-\\nu}}exp \\left(-\\frac{1}{2\\sigma^2}(\\beta-\\hat{\\beta})'X'X(\\beta-\\hat{\\beta}) \\right) \\frac{1}{\\sigma^\\nu}exp \\left(-\\frac{s^2\\nu}{2\\sigma^2}\\right)$\n",
    "\n",
    "where\n",
    "\n",
    "$\\hat{\\beta}=(X'X)^{-1}X'y$\n",
    "\n",
    "$s^2=\\frac{(y-X\\hat{\\beta})'(y-X\\hat{\\beta})}{\\nu}$\n",
    "\n",
    "$\\nu=n-k$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Generate sample\n",
    "n = 100\n",
    "\n",
    "trueBeta = np.array([10,5])\n",
    "\n",
    "X = pd.DataFrame(index=range(n))\n",
    "X['x0']=np.ones(n)\n",
    "X['x1']=np.random.randn(n)\n",
    "# X['x2']=np.random.randn(n,1)*5+10\n",
    "# X['x3']=np.random.randn(n,1)*2-20\n",
    "\n",
    "y = pd.DataFrame(index=range(n))\n",
    "y['y']=np.dot(X,trueBeta)+np.random.randn(n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the prior\n",
    "Memo: prior is Normal-Inverted Gamma\n",
    "\n",
    "$$(\\beta,\\sigma^2) \\sim NIG \\left(\\underline{\\beta},\\underline{V},\\frac{1}{\\underline{\\sigma^2}},\\underline{\\nu} \\right)$$\n",
    "\n",
    "\n",
    "We can interpret the prior as\n",
    "\n",
    "$\\pi(\\beta,\\sigma^2) = \\pi_\\beta(\\beta \\mid \\sigma^2) \\times \\pi_\\sigma(\\sigma^2)$\n",
    "\n",
    "$\\beta \\mid \\sigma^2 \\sim N(\\beta_0,\\sigma^2V_0)$\n",
    "\n",
    "$\\sigma^2 \\sim IG \\left(\\frac{1}{\\sigma_0^2},\\nu_0 \\right)$\n",
    "\n",
    "That is, draw $\\sigma^2$ from IG, then draw $\\beta$ from N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Choosing the prior\n",
    "\n",
    "m = 1 #confidence in prior. The larger this number, the smaller the prior variance\n",
    "\n",
    "prior = {'b0': np.array([[9],\n",
    "                         [6]]),\n",
    "         'V0': 0.05/m * np.identity(2),\n",
    "         'sigma2_0':1,\n",
    "         'nu0':m }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.05  0.  ]\n",
      " [ 0.    0.05]]\n",
      "[[9]\n",
      " [6]]\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(prior['V0'])\n",
    "print(prior['b0'])\n",
    "print(prior['sigma2_0'])\n",
    "print(prior['nu0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the posterior\n",
    "Normal-Inverted Gamma is a conjugate prior, i.e. yields a Normal-Inverted Gamma posterior (with different hyperparameters)\n",
    "$$(\\beta,\\sigma^2 \\mid y,X) \\sim NIG \\left(\\overline{\\beta},\\overline{V},\\frac{1}{\\overline{\\sigma^2}},\\overline{\\nu} \\right)$$\n",
    "\n",
    "where\n",
    "\n",
    "$\\overline{V} = \\left( \\underline{V}^{-1}+X'X \\right)^{-1}$\n",
    "\n",
    "$\\overline{\\beta} = \\overline{V} \\left( \\underline{V}^{-1}\\underline{\\beta}+X'X\\hat{\\beta} \\right)$\n",
    "\n",
    "$\\overline{\\nu} = \\underline{\\nu}+n$\n",
    "\n",
    "$\\overline{\\sigma}^2 = \\frac{1}{\\overline{\\nu}} \\left(\\underline{\\nu \\sigma}^2 +(n-k)s^2+ (\\hat{\\beta}-\\underline{\\beta})'(\\underline{V}+(X'X)^{-1})(\\hat{\\beta}-\\underline{\\beta}) \\right) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta:\n",
      "[[ 9.81085477]\n",
      " [ 5.22525282]]\n",
      "\n",
      "V:\n",
      "[[ 0.00862388 -0.00164656]\n",
      " [-0.00164656  0.00933139]]\n",
      "\n",
      "nu: 101\n",
      "\n",
      "sigma2: [[ 1.17337512]]\n"
     ]
    }
   ],
   "source": [
    "class NLRM(object):\n",
    "    def __init__(self,Y,X,prior):\n",
    "        self.g(Y,X,prior)\n",
    "    def g(self,Y,X,prior):\n",
    "        # OLS beta estimator\n",
    "        b_hat = np.dot(np.dot(np.linalg.inv(np.dot(np.transpose(X),X)),np.transpose(X)),y)\n",
    "        \n",
    "        n = X.shape[0]\n",
    "        k = X.shape[1]\n",
    "        \n",
    "        s2 = np.dot(np.transpose(y-np.dot(X,b_hat)),y-np.dot(X,b_hat))/(n-k)\n",
    "        \n",
    "        V = np.linalg.inv(np.linalg.inv(prior['V0'])+np.dot(np.transpose(X),X))\n",
    "        \n",
    "        b = np.dot(V,(np.dot(np.linalg.inv(prior['V0']),prior['b0'])+np.dot(np.dot(np.transpose(X),X),b_hat)))\n",
    "        \n",
    "        nu = prior['nu0'] + n\n",
    "        sigma2 = 1/nu * (prior['nu0']*prior['sigma2_0'] + (n-k)*s2 + \n",
    "                        np.dot(np.dot(np.transpose(b_hat-b),\n",
    "                                      prior['V0']+np.linalg.inv(np.dot(np.transpose(X),X))),\n",
    "                              b_hat-b))\n",
    "        \n",
    "        self.b_hat = b_hat\n",
    "        self.s2 = s2\n",
    "        self.V = V\n",
    "        self.b = b\n",
    "        self.nu = nu\n",
    "        self.sigma2 = sigma2\n",
    "\n",
    "### test\n",
    "model = NLRM(y,X,prior)\n",
    "\n",
    "print('beta:')\n",
    "print(model.b)\n",
    "print('')\n",
    "print('V:')\n",
    "print(model.V)\n",
    "print('')\n",
    "print('nu: '+str(model.nu))\n",
    "print('')\n",
    "print('sigma2: '+str(model.sigma2))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
